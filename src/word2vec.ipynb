{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, pdb\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from itertools import ifilter\n",
    "from IPython.core.debugger import set_trace\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 200000\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, hid_dim, pretrained=None):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        #these are by intent to learn separate embedding matrices, we return word_emb\n",
    "        self.word_emb = nn.Embedding(vocab_size, hid_dim)\n",
    "        if pretrained is not None:\n",
    "            self.word_emb.weight.data.copy_(pretrained)\n",
    "        self.context_emb = nn.Embedding(vocab_size, hid_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, wrd, cntxt):\n",
    "        wrd_vec = self.word_emb(wrd) # N * 1 * D\n",
    "        cntxt_vec = self.context_emb(cntxt) # N * 5 * D\n",
    "        res = torch.bmm(wrd_vec, cntxt_vec.view(BATCH_SIZE, self.hid_dim, -1))\n",
    "        res = self.sigmoid(res) # N * 1 * 5\n",
    "        res = res.squeeze(1) # for each mini-batch we have a probability score for the 5 contexts\n",
    "        return res\n",
    "        \n",
    "def process_data(min_freq, flName=None, lines=None):\n",
    "    \"\"\"\n",
    "    flName: file to read which contain raw data\n",
    "    min_freq: required minimum frequency to be considered in vocabulary\n",
    "    returns: vocab, vocab_size, word2index, index2word\n",
    "    \"\"\"\n",
    "    vocab, index2word, word2index = {}, {}, {}\n",
    "    if flName is not None:\n",
    "        with open(flName) as fp:\n",
    "            lines = fp.readlines()\n",
    "            \n",
    "    for line in lines:\n",
    "        wrds = line.split(\" \") #a very basic tokenizer that only splits by space and no stemming or cleaning\n",
    "        for w in wrds:\n",
    "            if w not in vocab:\n",
    "                vocab[w] = 1\n",
    "            else:\n",
    "                vocab[w] += 1\n",
    "\n",
    "    for wrd in vocab:\n",
    "        if vocab[wrd] >= min_freq:\n",
    "            index2word[len(index2word)] = wrd\n",
    "            word2index[wrd] = len(index2word) - 1\n",
    "        else:\n",
    "            vocab[wrd] = 0\n",
    "    vocab_size = len(index2word)\n",
    "    return vocab, vocab_size, word2index, index2word\n",
    "\n",
    "def negative_sampling_tbl(vocab, vocab_size, idx2word):\n",
    "    total_cn = 0\n",
    "    for wrd in vocab:\n",
    "        total_cn += pow(vocab[wrd],0.75)\n",
    "        \n",
    "    tbl_size, wrd_idx = int(1e8), 0\n",
    "    table = torch.LongTensor(tbl_size) # defaults to a column vector with only 1 dimension\n",
    "    wrd_prob = pow(vocab[idx2word[wrd_idx]], 0.75)/total_cn\n",
    "    \n",
    "    for i in range(0, tbl_size):\n",
    "        table[i] = wrd_idx\n",
    "        if i/tbl_size > wrd_prob:\n",
    "            wrd_idx += 1\n",
    "            wrd_prob += pow(vocab[idx2word[wrd_idx]], 0.75)/total_cn\n",
    "        if wrd_idx >= vocab_size:\n",
    "            wrd_idx -= 1\n",
    "    \n",
    "    return table\n",
    "        \n",
    "# return the sample context the first one being the true word and other being negative\n",
    "def sample_context(table, neg_cn, cntxt):\n",
    "    cntxts, i = [], 0\n",
    "    cntxts.append(cntxt)\n",
    "    while i < neg_cn:\n",
    "        ind = randint(0, len(table) - 1)\n",
    "        neg_ctx = table[ind]\n",
    "        if neg_ctx != cntxt:\n",
    "            cntxts.append(neg_ctx)\n",
    "            i += 1\n",
    "    return cntxts\n",
    "\n",
    "\n",
    "def train_pair(wrd_idx, cntxts, labels, mdl, criterion, optimizer):\n",
    "    \"\"\"\n",
    "        wrd_idx: is the input word which is predicting the context\n",
    "        cntxts: contains 1 positive word idx's and remaining negative words idx's forming the context\n",
    "    \"\"\"\n",
    "    preds = mdl(wrd_idx, cntxts)\n",
    "    loss = criterion(preds, labels)    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data[0]\n",
    "    \n",
    "def train_model(mdl, lines, table=None, neg_exmpl=10, win_size=5):\n",
    "    print('Training..')\n",
    "    if table is None:\n",
    "        table = negative_sampling_tbl(vocab, vocab_size, index2word)\n",
    "    print('Data processing complete..')\n",
    "    # by default it will give a float tensor, the first one is the positive, remaining are negative\n",
    "    labels = Variable(torch.zeros(BATCH_SIZE, 1 + neg_exmpl))\n",
    "    labels[:, 0] = 1\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        labels = labels.cuda()\n",
    "        table = table.cuda()\n",
    "        mdl.cuda()\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(mdl.parameters(), lr=0.025)\n",
    "    \n",
    "    track_loss, batch_wrd_idx, batch_cntxts = [], [], []\n",
    "    for k, l in enumerate(lines):\n",
    "        l = l.strip()\n",
    "        wrds = l.split(\" \")        \n",
    "        #print(\"line:\", k)\n",
    "        for i, wrd in enumerate(wrds):\n",
    "            #print(\"wrd:\", i)\n",
    "            if wrd in word2index:\n",
    "                # target word which is predicting its context                \n",
    "                wrd_idx = word2index[wrd]\n",
    "                \n",
    "                # for training word i searching for other words j in vicinity as its context\n",
    "                # for ppdb its singleton, for story its multiple                \n",
    "                for j in range(max(0, i - win_size), min(len(wrds), i + win_size)):\n",
    "                    #print(\"cntxt:\", j)\n",
    "                    cntxt_wrd = l[j] #it's guarenteed to be a valid index\n",
    "                    if j != i and cntxt_wrd in word2index:\n",
    "                        cntxt_idx = word2index[cntxt_wrd]\n",
    "                        cntxts = sample_context(table, neg_exmpl, cntxt_idx)\n",
    "                        \n",
    "                        batch_wrd_idx.append(wrd_idx)\n",
    "                        batch_cntxts.append(cntxts)\n",
    "                        \n",
    "                        if len(batch_wrd_idx) == BATCH_SIZE:\n",
    "                            print(\"line:\", i, j, k)\n",
    "                            var_wrd_idx = Variable(torch.LongTensor(batch_wrd_idx)).unsqueeze(1)\n",
    "                            var_cntxts = Variable(torch.LongTensor(batch_cntxts))\n",
    "\n",
    "                            if torch.cuda.is_available():\n",
    "                                var_wrd_idx = var_wrd_idx.cuda()\n",
    "                                var_cntxts = var_cntxts.cuda()\n",
    "                            \n",
    "                            lossval = train_pair(var_wrd_idx, var_cntxts, labels, mdl, criterion, optimizer)\n",
    "                            print('loss:', lossval)\n",
    "                            track_loss.append(lossval)\n",
    "                            batch_wrd_idx[:], batch_cntxts[:] = [], []\n",
    "                            \n",
    "    return sum(track_loss)/len(track_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sim(wrd, k, mat, word2index):\n",
    "    if wrd not in word2index:\n",
    "        return None\n",
    "    vec = mat[word2index[wrd], :].unsqueeze(1)\n",
    "    othrs = torch.mm(mat, vec)\n",
    "    othrs, ind = torch.sort(othrs, 0, descending=True)\n",
    "    topk = ind[:k]\n",
    "    for i in range(topk.size()[0]):\n",
    "        print(index2word[topk[i][0]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(wrd1, wrd2, mat):\n",
    "    if wrd1 not in word2index or wrd2 not in word2index:\n",
    "        return 0.0\n",
    "    vec1 = mat[word2index[wrd1]]\n",
    "    vec2 = mat[word2index[wrd2]]\n",
    "    return torch.dot(vec2, vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"ppdb-2.0-xl-lexical\", \"r\") as fp:\n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for l in lines:\n",
    "    dt = l.split(\"|||\")\n",
    "    score = float(dt[3].split(\" \")[1].split(\"=\")[1])\n",
    "    if score < 3.7:\n",
    "        continue\n",
    "    wrd1, wrd2 = dt[1], dt[2]\n",
    "    wrd1, wrd2 = wrd1.strip(), wrd2.strip()\n",
    "    if \".pdf\" not in wrd1:\n",
    "        pairs.append(wrd1 + \" \" + wrd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab, vocab_size, word2index, index2word = process_data(1, lines=pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65256"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl = Word2Vec(vocab_size, 300)\n",
    "mdl.load_state_dict(torch.load('./mdl_preglove_300d.pth'))\n",
    "w2vmat = torch.nn.functional.normalize(mdl.word_emb.weight.data.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "1.00000e-02 *\n",
       " -0.3246\n",
       " -0.2606\n",
       "  0.0572\n",
       "  0.1338\n",
       "  0.2410\n",
       " -0.1656\n",
       "  0.0540\n",
       "  0.1766\n",
       "  0.3145\n",
       "  0.4376\n",
       "  0.0207\n",
       " -0.0702\n",
       " -0.1342\n",
       "  0.0599\n",
       " -0.0723\n",
       " -0.5322\n",
       "  0.3899\n",
       "  0.4913\n",
       " -0.2826\n",
       " -0.4947\n",
       "  0.2850\n",
       "  0.1287\n",
       " -0.3109\n",
       "  0.4558\n",
       " -0.3521\n",
       " -0.1082\n",
       "  0.1826\n",
       " -0.1000\n",
       " -0.4710\n",
       " -0.7047\n",
       "  0.2641\n",
       "  0.3973\n",
       "  0.3069\n",
       " -1.0578\n",
       "  0.1623\n",
       "  0.4239\n",
       " -0.3341\n",
       "  0.1033\n",
       " -0.0524\n",
       " -0.4932\n",
       "  0.2178\n",
       "  0.2346\n",
       " -0.1333\n",
       " -0.0506\n",
       " -0.1475\n",
       "  0.3552\n",
       "  0.4031\n",
       " -0.6859\n",
       "  0.1984\n",
       "  0.3102\n",
       " -0.3771\n",
       "  0.1117\n",
       "  0.1921\n",
       " -0.5297\n",
       "  0.0224\n",
       "  0.4189\n",
       " -0.1848\n",
       "  0.0406\n",
       " -0.6146\n",
       "  0.2082\n",
       "  0.3086\n",
       " -0.5745\n",
       " -0.1329\n",
       "  0.0960\n",
       "  0.0523\n",
       " -0.3201\n",
       "  0.2758\n",
       " -0.2357\n",
       " -0.0274\n",
       "  0.3173\n",
       "  0.1876\n",
       "  0.1278\n",
       " -0.0896\n",
       "  0.3192\n",
       "  0.5792\n",
       " -0.2303\n",
       " -0.5949\n",
       "  0.2732\n",
       "  0.5696\n",
       " -0.3904\n",
       "  0.3003\n",
       "  0.0063\n",
       " -0.2350\n",
       "  0.0146\n",
       "  0.3733\n",
       " -0.0701\n",
       "  0.1105\n",
       "  0.2877\n",
       "  0.2795\n",
       "  0.0150\n",
       " -0.9621\n",
       "  0.1570\n",
       "  0.2720\n",
       " -0.3763\n",
       "  0.1755\n",
       "  0.1365\n",
       " -0.3675\n",
       "  0.0715\n",
       "  0.2293\n",
       " -0.1106\n",
       "  0.2469\n",
       " -0.3127\n",
       "  0.5633\n",
       "  0.2982\n",
       " -1.0295\n",
       " -0.2881\n",
       "  0.3117\n",
       " -0.0708\n",
       "  0.0244\n",
       "  0.1247\n",
       " -0.5291\n",
       " -0.0186\n",
       "  0.3586\n",
       " -0.2451\n",
       " -0.0407\n",
       " -0.5322\n",
       "  0.3899\n",
       "  0.4913\n",
       " -0.2826\n",
       " -0.4947\n",
       "  0.2850\n",
       "  0.1287\n",
       " -0.3109\n",
       "  0.4558\n",
       " -0.3521\n",
       " -0.1082\n",
       "  0.1826\n",
       " -0.1000\n",
       " -0.4711\n",
       " -0.7048\n",
       "  0.2641\n",
       "  0.3973\n",
       "  0.3069\n",
       " -1.0578\n",
       "  0.1621\n",
       "  0.4240\n",
       " -0.3341\n",
       "  0.1033\n",
       " -0.0524\n",
       " -0.4932\n",
       "  0.2179\n",
       "  0.2348\n",
       " -0.1333\n",
       " -0.0507\n",
       " -0.1469\n",
       "  0.3550\n",
       "  0.4031\n",
       " -0.6859\n",
       "  0.1984\n",
       "  0.3102\n",
       " -0.3772\n",
       "  0.1118\n",
       "  0.1922\n",
       " -0.5295\n",
       "  0.0223\n",
       "  0.4187\n",
       " -0.1848\n",
       "  0.0407\n",
       " -0.6145\n",
       "  0.2082\n",
       "  0.3086\n",
       " -0.5745\n",
       " -0.1330\n",
       "  0.0960\n",
       "  0.0523\n",
       " -0.3200\n",
       "  0.2758\n",
       " -0.2358\n",
       " -0.0274\n",
       "  0.3174\n",
       "  0.1880\n",
       "  0.1282\n",
       " -0.0901\n",
       "  0.3191\n",
       "  0.5792\n",
       " -0.2305\n",
       " -0.5949\n",
       "  0.2732\n",
       "  0.5698\n",
       " -0.3905\n",
       "  0.3003\n",
       "  0.0065\n",
       " -0.2350\n",
       "  0.0144\n",
       "  0.3733\n",
       " -0.0701\n",
       "  0.1105\n",
       "  0.2877\n",
       "  0.2796\n",
       "  0.0150\n",
       " -0.9621\n",
       "  0.1569\n",
       "  0.2719\n",
       " -0.3763\n",
       "  0.1755\n",
       "  0.1365\n",
       " -0.3674\n",
       "  0.0715\n",
       "  0.2293\n",
       " -0.1106\n",
       "  0.2472\n",
       " -0.3128\n",
       "  0.5632\n",
       "  0.2981\n",
       " -1.0295\n",
       " -0.2881\n",
       "  0.3117\n",
       " -0.0707\n",
       "  0.0244\n",
       "  0.1247\n",
       " -0.5292\n",
       " -0.0187\n",
       "  0.3586\n",
       " -0.2452\n",
       " -0.0407\n",
       " -0.5322\n",
       "  0.3899\n",
       "  0.4913\n",
       " -0.2826\n",
       " -0.4947\n",
       "  0.2850\n",
       "  0.1287\n",
       " -0.3109\n",
       "  0.4558\n",
       " -0.3521\n",
       " -0.1082\n",
       "  0.1826\n",
       " -0.1000\n",
       " -0.4711\n",
       " -0.7047\n",
       "  0.2641\n",
       "  0.3973\n",
       "  0.3068\n",
       " -1.0578\n",
       "  0.1621\n",
       "  0.4240\n",
       " -0.3341\n",
       "  0.1033\n",
       " -0.0524\n",
       " -0.4932\n",
       "  0.2178\n",
       "  0.2348\n",
       " -0.1335\n",
       " -0.0507\n",
       " -0.1475\n",
       "  0.3550\n",
       "  0.4031\n",
       " -0.6859\n",
       "  0.1986\n",
       "  0.3102\n",
       " -0.3771\n",
       "  0.1117\n",
       "  0.1921\n",
       " -0.5295\n",
       "  0.0224\n",
       "  0.4188\n",
       " -0.1848\n",
       "  0.0407\n",
       " -0.6145\n",
       "  0.2082\n",
       "  0.3085\n",
       " -0.5745\n",
       " -0.1330\n",
       "  0.0960\n",
       "  0.0524\n",
       " -0.3200\n",
       "  0.2758\n",
       " -0.2357\n",
       " -0.0273\n",
       "  0.3173\n",
       "  0.1879\n",
       "  0.1281\n",
       " -0.0896\n",
       "  0.3193\n",
       "  0.5793\n",
       " -0.2303\n",
       " -0.5952\n",
       "  0.2732\n",
       "  0.5699\n",
       " -0.3901\n",
       "  0.3003\n",
       "  0.0063\n",
       " -0.2350\n",
       "  0.0146\n",
       "  0.3733\n",
       " -0.0701\n",
       "  0.1106\n",
       "  0.2877\n",
       "  0.2795\n",
       "  0.0150\n",
       " -0.9622\n",
       "  0.1569\n",
       "  0.2718\n",
       " -0.3763\n",
       "  0.1755\n",
       "  0.1366\n",
       " -0.3674\n",
       "  0.0715\n",
       "  0.2292\n",
       " -0.1105\n",
       "[torch.FloatTensor of size 300]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.word_emb.weight.data.cpu()[word2index['the'], :]  - pretrained_weight[word2index['the'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "man\n",
      "whose\n",
      "woman\n",
      "boy\n",
      "father\n",
      "another\n",
      "home\n",
      "a\n",
      "who\n"
     ]
    }
   ],
   "source": [
    "get_sim('old', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "ho\n",
      "ai\n",
      "tu\n",
      "se\n",
      "na\n",
      "yo\n",
      "ti\n",
      "brasil\n",
      "ya\n"
     ]
    }
   ],
   "source": [
    "get_sim('hi', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep\n",
      "breathing\n",
      "sleeping\n",
      "pain\n",
      "dying\n",
      "awake\n",
      "breath\n",
      "patient\n",
      "sick\n",
      "waking\n"
     ]
    }
   ],
   "source": [
    "get_sim('sleep', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "young\n",
      "keenly\n",
      "blimp\n",
      "draconian\n",
      "koruna\n",
      "keep\n",
      "coexistence\n",
      "2003-2006\n",
      "bst\n",
      "lowlife\n"
     ]
    }
   ],
   "source": [
    "get_sim('young', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep\n",
      "squeamish\n",
      "rayon\n",
      "elites\n",
      "deselect\n",
      "tucked\n",
      "partenaire\n",
      "snakes\n",
      "co-occurring\n",
      "india\n"
     ]
    }
   ],
   "source": [
    "get_sim('sleep', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "foreign-currency\n",
      "min\n",
      "24.6\n",
      "hijacks\n",
      "stadiums\n",
      "outset\n",
      "zia\n",
      "toil\n",
      "my-\n"
     ]
    }
   ],
   "source": [
    "get_sim('hi', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n",
      "netanyahu\n",
      "anti-poverty\n",
      "bias-free\n",
      "persecutes\n",
      "marvin\n",
      "bap\n",
      "spanner\n",
      "cancellable\n",
      "benevolent\n"
     ]
    }
   ],
   "source": [
    "get_sim('old', 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
